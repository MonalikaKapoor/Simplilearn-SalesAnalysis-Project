{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1724df",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Sales Analysis - Full Python Script\n",
    "Author: Monalika Kapoor\n",
    "Purpose: \n",
    " - Performs data wrangling (missing values, parsing dates)\n",
    " - Normalizes numeric columns (Min-Max)\n",
    " - Performs descriptive stats for Sales and Unit\n",
    " - Aggregates by State and Group and by time (daily/weekly/monthly/quarterly)\n",
    " - Produces and saves visualizations and CSV outputs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb205c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# IMPORT LIBRARIES\n",
    "# ----------------------------------------------\n",
    "# Library\tPurpose\n",
    "# pandas\tLoad & manipulate CSV data\n",
    "# numpy\tNumerical computation\n",
    "# Pathlib\tClean file path handling\n",
    "# MinMaxScaler\tNormalization of numeric columns\n",
    "# matplotlib/seaborn\tData visualization & charts\n",
    "# DateFormatter\tFormat time-based axis in plots\n",
    "# warnings\tSuppress irrelevant warnings\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "from pathlib import Path\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# Ignore warnings for cleaner outputs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc09a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n",
      "Shape: (7560, 6)\n",
      "Columns: ['Date', 'Time', 'State', 'Group', 'Unit', 'Sales']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# LOAD DATA\n",
    "# ----------------------------------------------   \n",
    "DATA_PATH = Path(\"AusApparalSales4thQrt2020.csv\")# <-- using your uploaded CSV\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "OUTPUT_DIR = Path(\"sales_analysis_output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Data Loaded Successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d497d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected Columns:\n",
      "Date: Date\n",
      "Sales: Sales\n",
      "Units: Unit\n",
      "State: State\n",
      "Group: Group\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# DETECT COLUMNS AUTOMATICALLY\n",
    "# ----------------------------------------------\n",
    "def detect_columns(df):\n",
    "    cols = df.columns\n",
    "    date_col = next((c for c in cols if \"date\" in c.lower()), None)\n",
    "    sales_col = next((c for c in cols if c.lower() == \"sales\"), None)\n",
    "    unit_col = next((c for c in cols if \"unit\" in c.lower()), None)\n",
    "    state_col = next((c for c in cols if \"state\" in c.lower()), None)\n",
    "    group_col = next((c for c in cols if \"group\" in c.lower()), None)\n",
    "    return date_col, sales_col, unit_col, state_col, group_col\n",
    "\n",
    "DATE_COL, SALES_COL, UNIT_COL, STATE_COL, GROUP_COL = detect_columns(df)\n",
    "print(\"\\nDetected Columns:\")\n",
    "print(\"Date:\", DATE_COL)\n",
    "print(\"Sales:\", SALES_COL)\n",
    "print(\"Units:\", UNIT_COL)\n",
    "print(\"State:\", STATE_COL)\n",
    "print(\"Group:\", GROUP_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ffbe9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Summary:\n",
      "Date          0\n",
      "Time          0\n",
      "State         0\n",
      "Group         0\n",
      "Unit          0\n",
      "Sales         0\n",
      "ParsedDate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------------------------\n",
    "# DATA WRANGLING\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Parse dates\n",
    "df[\"ParsedDate\"] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "# Missing value check\n",
    "print(\"\\nMissing Values Summary:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Fill numeric missing with median\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Fill categorical missing with 'Unknown'\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col].fillna(\"Unknown\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7377e00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalization Complete!\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# NORMALIZATION (Min–Max Scaling)\n",
    "# ----------------------------------------------\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized = scaler.fit_transform(df[numeric_cols])\n",
    "normalized_df = pd.DataFrame(normalized, columns=[f\"{c}_norm\" for c in numeric_cols])\n",
    "\n",
    "df = pd.concat([df, normalized_df], axis=1)\n",
    "\n",
    "normalized_df.head(20).to_csv(OUTPUT_DIR/\"normalized_sample.csv\", index=False)\n",
    "\n",
    "print(\"\\nNormalization Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9322e3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics – Sales:\n",
      "count      7560.000000\n",
      "mean      45013.558201\n",
      "std       32253.506944\n",
      "min        5000.000000\n",
      "25%       20000.000000\n",
      "50%       35000.000000\n",
      "75%       65000.000000\n",
      "max      162500.000000\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "Descriptive Statistics – Units:\n",
      "count    7560.000000\n",
      "mean       18.005423\n",
      "std        12.901403\n",
      "min         2.000000\n",
      "25%         8.000000\n",
      "50%        14.000000\n",
      "75%        26.000000\n",
      "max        65.000000\n",
      "Name: Unit, dtype: float64\n",
      "\n",
      "Top States by Sales:\n",
      " State\n",
      "VIC    105565000\n",
      "NSW     74970000\n",
      "SA      58857500\n",
      "QLD     33417500\n",
      "TAS     22760000\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "Bottom States by Sales:\n",
      " State\n",
      "SA     58857500\n",
      "QLD    33417500\n",
      "TAS    22760000\n",
      "NT     22580000\n",
      "WA     22152500\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "Top Groups by Sales:\n",
      " Group\n",
      "Men        85750000\n",
      "Women      85442500\n",
      "Kids       85072500\n",
      "Seniors    84037500\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "Bottom Groups by Sales:\n",
      " Group\n",
      "Men        85750000\n",
      "Women      85442500\n",
      "Kids       85072500\n",
      "Seniors    84037500\n",
      "Name: Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# DESCRIPTIVE STATISTICS\n",
    "# ----------------------------------------------\n",
    "print(\"\\nDescriptive Statistics – Sales:\")\n",
    "print(df[SALES_COL].describe())\n",
    "\n",
    "print(\"\\nDescriptive Statistics – Units:\")\n",
    "print(df[UNIT_COL].describe())\n",
    "\n",
    "# ----------------------------------------------\n",
    "# HIGHEST & LOWEST SALES (STATE + GROUP)\n",
    "# ----------------------------------------------\n",
    "state_sales = df.groupby(STATE_COL)[SALES_COL].sum().sort_values(ascending=False)\n",
    "group_sales = df.groupby(GROUP_COL)[SALES_COL].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop States by Sales:\\n\", state_sales.head())\n",
    "print(\"\\nBottom States by Sales:\\n\", state_sales.tail())\n",
    "print(\"\\nTop Groups by Sales:\\n\", group_sales.head())\n",
    "print(\"\\nBottom Groups by Sales:\\n\", group_sales.tail())\n",
    "\n",
    "state_sales.to_csv(OUTPUT_DIR/\"state_total_sales.csv\")\n",
    "group_sales.to_csv(OUTPUT_DIR/\"group_total_sales.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628c1ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time-Based Reports Generated!\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# TIME-BASED REPORTING\n",
    "# ----------------------------------------------\n",
    "df = df.set_index(\"ParsedDate\")\n",
    "\n",
    "daily = df[SALES_COL].resample(\"D\").sum()\n",
    "weekly = df[SALES_COL].resample(\"W\").sum()\n",
    "monthly = df[SALES_COL].resample(\"M\").sum()\n",
    "quarterly = df[SALES_COL].resample(\"Q\").sum()\n",
    "\n",
    "daily.to_csv(OUTPUT_DIR/\"daily_sales.csv\")\n",
    "weekly.to_csv(OUTPUT_DIR/\"weekly_sales.csv\")\n",
    "monthly.to_csv(OUTPUT_DIR/\"monthly_sales.csv\")\n",
    "quarterly.to_csv(OUTPUT_DIR/\"quarterly_sales.csv\")\n",
    "\n",
    "print(\"\\nTime-Based Reports Generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0680eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizations Saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# VISUALIZATION\n",
    "# ----------------------------------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1) State-wise sales by group\n",
    "pivot_table = df.pivot_table(values=SALES_COL, index=STATE_COL, columns=GROUP_COL, aggfunc=\"sum\", fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "pivot_table.plot(kind=\"bar\")\n",
    "plt.title(\"State-wise Sales by Group\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR/\"state_group_sales.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2) Total sales by group\n",
    "plt.figure(figsize=(8,5))\n",
    "group_sales.plot(kind=\"bar\")\n",
    "plt.title(\"Total Sales by Group\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR/\"group_sales.png\")\n",
    "plt.close()\n",
    "\n",
    "# 3) Daily Sales Trend\n",
    "plt.figure(figsize=(10,5))\n",
    "daily.plot()\n",
    "plt.title(\"Daily Sales Trend\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR/\"daily_sales_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# 4) Boxplot (Sales & Units)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=df[[SALES_COL, UNIT_COL]])\n",
    "plt.title(\"Boxplot - Sales & Units\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR/\"boxplot_sales_units.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nVisualizations Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32b20c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Markdown Report Generated Successfully!\n",
      "\n",
      "All outputs saved to: sales_analysis_output\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# REPORT GENERATION (MARKDOWN)\n",
    "# ----------------------------------------------\n",
    "with open(OUTPUT_DIR/\"summary_report.md\",\"w\") as f:\n",
    "    f.write(\"# Sales Analysis Report\\n\")\n",
    "    f.write(\"Dataset: AusApparalSales4thQrt2020.csv\\n\\n\")\n",
    "    f.write(\"## Detected Columns\\n\")\n",
    "    f.write(f\"- Date Column: {DATE_COL}\\n\")\n",
    "    f.write(f\"- Sales Column: {SALES_COL}\\n\")\n",
    "    f.write(f\"- Units Column: {UNIT_COL}\\n\")\n",
    "    f.write(f\"- State Column: {STATE_COL}\\n\")\n",
    "    f.write(f\"- Group Column: {GROUP_COL}\\n\\n\")\n",
    "\n",
    "    f.write(\"## Top States by Sales\\n\")\n",
    "    f.write(state_sales.head().to_markdown() + \"\\n\\n\")\n",
    "\n",
    "    f.write(\"## Top Groups by Sales\\n\")\n",
    "    f.write(group_sales.head().to_markdown() + \"\\n\\n\")\n",
    "\n",
    "print(\"\\nMarkdown Report Generated Successfully!\")\n",
    "print(\"\\nAll outputs saved to:\", OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sales_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
